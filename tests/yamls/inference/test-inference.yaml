kind: inference
version: v0.1

# 任务标识
job:
  name: new-test-inference-job
  priority: "medium"
  description: "测试推理任务"

# 环境与镜像
environment:
  image: vllm/vllm-openai:v0.12.0
  command: ["python", "-m", "vllm.entrypoints.openai.api_server"]
  args:
    - "--model"
    - "/home/data/models/llama3-8b"
    - "--tensor-parallel-size"
    - "1"
  env:
    - name: NVIDIA_FLASH_ATTENTION
      value: "1"

# 服务配置
service:
  replicas: 1
  port: 8000
  healthCheck: /health

# 资源规格
resources:
  pool: test-pool
  #gpu: 1
  #gpuType: a10-24g
  cpu: 1
  memory: 2Gi
  gpuShare: 2Gi

storage:
  workdirs:
    - path: /home/data/